---
id: nvidia-gpu-operator
title: nvidia-gpu-operator
sidebar_label: nvidia-gpu-operator
description: nvidia-gpu-operator
keywords:
  - nvidia-gpu-operator
---

## Installation

```shell
helm repo add nvidia https://nvidia.github.io/gpu-operator \
&& helm repo update nvidia
```

```shell
helm search repo gpu-operator -l | head -n 10
```

```shell
mkdir -p node/gpu-operator/helm
```

```shell
helm show values nvidia/gpu-operator \
    --version v1.9.1 \
    > node/gpu-operator/helm/values.yaml
```

[https://github.com/NVIDIA/gpu-operator/blob/master/deployments/gpu-operator/values.yaml](https://github.com/NVIDIA/gpu-operator/blob/master/deployments/gpu-operator/values.yaml)

- NVIDIA driver
- NVIDIA driver manager
- NVIDIA container toolkit
- NVIDIA k8s device plugin
- NVIDIA dcgm-exporter
- NFD(Node Feature Discovery)
- NVIDIA GPU Feature Discovery # NFD가 설치되어 있어야 함
- NVIDIA MIG(Multi-Instance GPU) manager
- NVIDIA DCGM(Data Center GPU Manager)

```yaml title="node/gpu-operator/helm/values.yaml"
driver:
  # NVIDIA driver가 Node에 설치되어 실행되는 경우 false로 설정
  enabled: fasle

toolkit:
  # nvidia-docker2가 Node에 설치되어 실행되는 경우 false로 설정
  enabled: false
```

```shell
helm upgrade gpu-operator nvidia/gpu-operator \
    --install \
    --version v1.9.1 \
    -n nvidia \
    --create-namespace \
    -f node/gpu-operator/helm/values.yaml
```

:::info
NFD와 GFD에 의해 Node label에 시스템 정보가 추가되며, 이를 `nodeAffinity`에 설정하여 사용할 수 있습니다.

```shell
kubectl get node -o json | jq '.items[].metadata.labels'
```

```shell
kubectl get node -o json | jq '.items[].metadata.annotations'
```

:::

## Removal

```shell
helm uninstall gpu-operator -n nvidia
```

## Reference

- [https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html#install-nvidia-gpu-operator](https://docs.nvidia.com/datacenter/cloud-native/gpu-operator/getting-started.html#install-nvidia-gpu-operator)
- [https://github.com/NVIDIA/gpu-operator](https://github.com/NVIDIA/gpu-operator)
