---
id: pg
title: Ceph Placement Group(PG) 관리
sidebar_label: PG 관리
description: Ceph Placement Group(PG) 관리
keywords:
  - ceph
  - pg
---

## Placement Group(PG)

- [Data 흐름](/docs/mlops/storage/ceph/osd#data-흐름)

OSD당 100 개의 PG를 갖는 것이 권장되며, PG 수는(**pg_num**)은 2의 거듭제곱으로 설정해야합니다.

```shell
            (OSDs) * 100
Total PGs = ------------
              pool size
```

pool size는 복제본 수 또는 EC의 K+M 값입니다. OSD 200 개에 복제본 3 개를 갖는 pool의 PG는 `(200 * 100)/ 3 = 6667 <= 8192`으로 계산될 수 있습니다.

## PG AutoScale

:::info[Reference]

- [Ceph / Operations / Placement Groups # Autoscaling placement groups](https://docs.ceph.com/en/latest/rados/operations/placement-groups/#autoscaling-placement-groups)

:::

```shell
kubectl rook-ceph ceph osd pool set <pool> <option> <value>
```

- `<option>`: `<value>`
  - `pg_autoscale_mode`: `on`|`warn`|`off`
  - `target_size_bytes`: `<targetSize>`
  - `target_size_ratio`: `<targetRatio>`
    - `target_size_bytes`보다 우선 순위가 높으므로, 둘 다 선언하면 `target_size_bytes`는 무시됩니다.
  - `bulk`: `<bool>`

```shell
kubectl rook-ceph ceph config set global mon_target_pg_per_osd 100
```

```shell
kubectl rook-ceph ceph osd pool autoscale-status
```

- **POOL**
- **SIZE**: 사용자가 저장한 데이터 크기입니다.
- **TARGET SIZE**
  - 관리자가 예상하는 `SIZE`입니다.
  - autoscaler는 max(targetSize, `실제 사용자가 저장한 데이터 크기`) 값을 고려합니다.
- **RATE**
  - `복제본 등을 포함한 데이터 크기`/`사용자가 저장한 데이터 크기` 입니다.
  - 단순히 `사용자가 저장한 데이터` + `복제본 1개`인 경우 2.0이 됩니다.
- **RAW CAPACITY**: CRUSH에 의해 pool이 매핑된 저장 장치의 총 용량입니다.
- **RATIO**: `SIZE` \* `RATE` / `RAW CAPACITY`
- **TARGET RATIO**: 관리자가 예상하는 `RATIO`입니다.
- **EFFECTIVE RATIO**
  - `TARGET SIZE`가 설정된 경우 예상되는 용량을 고려합니다.
  - `TARGET RATIO`값들을 정규화 합니다.
  - e.g., `TARGET RATIO`가 1.0인 pool이 2개가 있다면, 각각의 `EFFECTIVE RATIO`는 0.5가 됩니다.
- **BIAS**: 예상되는 PG_NUM에 곱해지는 가중치로, 1 보다 크면 더 많은 PG_NUM을 할당합니다.
- **PG_NUM**
- **NEW PG_NUM**
- **AUTOSCALE**: `on`|`warning`|`off`
- **BULK**
  - `True`|`False`
  - `BULK` 설정되면 최대치에 가까운 PG_NUM을 할당하고, 상황에 따라 PG_NUM을 줄입니다.

## PG State

- creating
- peering
- active
- clean: PG에 있는 모든 Object의 복제본이 일치하는 상태입니다.
- degraded: PG에 있는 Object의 복제본이 일치하지 않는 상태입니다.
- recovering: OSD가 down되었다가 up되었을 때, 최신 상태로 복구하는 중인 상태입니다.
- backfilling
  - PG가 다른 OSD로 재배치되었을 때, 기존 OSD에서 변경된 OSD로 데이터를 복사하는 중인 상태입니다.
  - OSD가 새로 추가되었을 때, CRUSH는 PG들을 재배치하여 새로운 OSD를 바로 쓸 수 있도록 만듭니다.
  - 부하가 큰 작업입니다.
- remapped: Acting Set을 변경하는 중인 상태입니다.
- stale
