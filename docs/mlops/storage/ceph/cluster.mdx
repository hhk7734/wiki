---
id: cluster
title: Rook Ceph Cluster 생성하기
sidebar_label: Rook Ceph Cluster
description: Rook Ceph Cluster 생성하기
keywords:
  - rook
  - ceph
  - cluster
---

## CephCluster 생성

:::info[Reference]

- [Rook / CephCluster CRD](https://rook.io/docs/rook/latest-release/CRDs/Cluster/ceph-cluster-crd/)
- [Disk 준비](/docs/mlops/storage/ceph/osd)

:::

```yaml
apiVersion: ceph.rook.io/v1
kind: CephCluster
metadata:
  name: rook-ceph
  namespace: rook-ceph
spec:
  cephVersion:
    image: quay.io/ceph/ceph:v18.2.4
  cleanupPolicy:
    allowUninstallWithVolumes: false
    confirmation: ""
    sanitizeDisks:
      dataSource: zero
      iteration: 1
      method: quick
  dashboard:
    enabled: true
  dataDirHostPath: /var/lib/rook
  disruptionManagement:
    managePodBudgets: true
    osdMaintenanceTimeout: 30
    pgHealthCheckTimeout: 0
  healthCheck:
    daemonHealth:
      mon:
        disabled: false
        interval: 45s
      osd:
        disabled: false
        interval: 60s
      status:
        disabled: false
        interval: 60s
  logCollector:
    enabled: true
    maxLogSize: 500M
    periodicity: daily
  mgr:
    count: 2
  mon:
    count: 3
  placement:
    all:
      tolerations: []
  priorityClassNames:
    mgr: system-cluster-critical
    mon: system-node-critical
    osd: system-node-critical
  resources:
    cleanup:
      limits:
        memory: 1Gi
      requests:
        memory: 100Mi
    crashcollector:
      limits:
        memory: 60Mi
      requests:
        memory: 60Mi
    exporter:
      limits:
        memory: 128Mi
      requests:
        memory: 50Mi
    logcollector:
      limits:
        memory: 1Gi
      requests:
        memory: 100Mi
    mgr:
      limits:
        memory: 1Gi
      requests:
        memory: 512Mi
    mgr-sidecar:
      limits:
        memory: 100Mi
      requests:
        memory: 40Mi
    mon:
      limits:
        memory: 2Gi
      requests:
        memory: 1Gi
    prepareosd:
      requests:
        memory: 50Mi
  storage:
    nodes:
      - name: ip-192-168-0-11
        devices:
          - name: /dev/vg1/lv1
    useAllDevices: false
    useAllNodes: false
```

- `spec`
  - `name: <clusterName>`: 한 namespace에는 하나의 CephCluster만 생성할 수 있으므로, 일반적으로 namespace와 같은 값을 설정합니다.

### cephConfig

:::info[Reference]

- [Rook / CephCluster CRD # Ceph Config](https://rook.io/docs/rook/latest-release/CRDs/Cluster/ceph-cluster-crd/#ceph-config)
- [Rook / Configuring Ceph](https://docs.ceph.com/en/reef/rados/configuration/ceph-conf/)

:::

```yaml
apiVersion: ceph.rook.io/v1
kind: CephCluster
spec:
  cephConfig:
    <section>:
      <key>: <value>
```

`cephConfig`는 MON이 실행된 후 적용됩니다.

- `<section>`
  - `global`, `mon`, `mgr`, `osd`, `mds`, `client` 등
  - `osd.<osdID>`, `mon.<monName>` 등 특정 Daemon을 지정할 수 있습니다.
  - 옵션이 중복되는 경우 범위가 좁은 것이 적용됩니다. 예를 들어 `global`, `osd`, `osd.1`에 중복 옵션이 있는 경우 `osd.1`이 적용됩니다.

<br />

- `kubectl rook-ceph ceph config dump`: MON 설정 DB를 출력합니다.
- `kubectl rook-ceph ceph config get <section> [<option>]`: MON 설정 DB나 컴파일 시 결정된 기본 값을 출력합니다.
- `kubectl rook-ceph ceph config show <section>`: 실행 중인 데몬의 설정을 출력합니다.

## CephCluster 삭제

:::info[Reference]

- [Rook / Cleanup](https://rook.io/docs/rook/latest-release/Getting-Started/ceph-teardown/)
- [Rook / CehpCluster CRD / Cleanup Policy](https://rook.io/docs/rook/latest-release/CRDs/Cluster/ceph-cluster-crd/#cleanup-policy)

:::

```shell
kubectl patch cephcluster rook-ceph \
    -n rook-ceph \
    --type merge \
    -p '{"spec":{"cleanupPolicy":{"confirmation":"yes-really-destroy-data"}}}'
```

```shell
kubectl delete cephcluster rook-ceph -n rook-ceph
```

Cluster 운영에 사용된 Node에 접속하여 `/var/lib/rook` 디렉토리를 정리합니다.

```yaml
- name: remove /var/lib/rook
  ansible.builtin.file:
    path: /var/lib/rook
    state: absent
```
