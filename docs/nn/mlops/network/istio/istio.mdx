---
id: istio
title: Istio
sidebar_label: Istio
description: Istio
keywords:
  - Istio
---

import useBaseUrl from "@docusaurus/useBaseUrl";

## Installation

```shell
asdf plugin add istioctl
```

```shell
asdf list all istioctl
```

```shell
asdf install istioctl 1.13.2
```

```shell
asdf global istioctl 1.13.2
```

```shell
asdf local istioctl 1.13.2
```

```shell
asdf current istioctl
```

```shell
export ISTIO_VERSION=1.13.2
```

```shell
helm repo add istio https://istio-release.storage.googleapis.com/charts
```

```shell
helm repo update istio \
&& helm search repo istio -l
```

```shell
kubectl create namespace istio-system
```

### base

```shell
helm show values istio/base \
    --version 1.13.2 \
    > istio-base-values.yaml
```

```yaml title="istio-base-values.yaml"
defaultRevision: 1-13-2
```

```shell
helm upgrade istio-base istio/base \
    --install \
    --version 1.13.2 \
    -n istio-system \
    -f istio-base-values.yaml
```

### istiod

```shell
helm show values istio/istiod \
    --version 1.13.2 \
    > istiod-1-13-2-values.yaml
```

```yaml title="istiod-1-13-2-values.yaml"
revision: 1-13-2
```

```shell
helm upgrade istiod istio/istiod \
    --install \
    --version 1.13.2 \
    -n istio-system \
    -f istiod-values.yaml
```

### ingressgateway

```shell
helm show values istio/gateway \
    --version 1.13.2 \
    > ingress-values.yaml
```

```yaml title="ingress-values.yaml"
service:
  ports:
    - port: 15021
      targetPort: 15021
      name: status-port
      protocol: TCP
      nodePort: <nodePort>
    - port: 80
      targetPort: 8080
      name: http2
      protocol: TCP
      nodePort: <nodePort>
    - port: 443
      targetPort: 8443
      name: https
      protocol: TCP
      nodePort: <nodePort>
  annotations:
    service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
    service.beta.kubernetes.io/aws-load-balancer-proxy-protocol: "*"
    proxy.istio.io/config: '{"gatewayTopology" : { "numTrustedProxies": 2 } }'
  externalTrafficPolicy: "Local"

autoscaling:
  enabled: true
  minReplicas: 2
  maxReplicas: 5
  targetCPUUtilizationPercentage: 80

affinity:
  podAntiAffinity:
    preferredDuringSchedulingIgnoredDuringExecution:
      - podAffinityTerm:
          labelSelector:
            matchExpressions:
              - key: app
                operator: In
                values:
                  - istio-ingress
          topologyKey: "kubernetes.io/hostname"
        weight: 50
```

:::info
https://istio.io/latest/docs/tasks/security/authorization/authz-ingress/#source-ip-address-of-the-original-client
:::

```shell
helm upgrade istio-ingress istio/gateway \
    --install \
    --version 1.13.2 \
    -n istio-system \
    -f ingress-values.yaml
```

## Removal

```shell
helm uninstall -n istio-system istio-ingress
```

```shell
helm uninstall -n istio-system istiod
```

```shell
helm uninstall -n istio-system istio-base
```

```shell
kubectl delete namespace istio-system
```

```shell
kubectl get crd -oname | grep --color=never 'istio.io' | xargs kubectl delete
```

## Proxy & Service mesh

<center>
  <img src={useBaseUrl("img/nn/mlops/mlops-istio-service-mesh-before.svg")} />
</center>

<center>
  <strong>Before utilizing Istio</strong>
</center>
<br />

<center>
  <img src={useBaseUrl("img/nn/mlops/mlops-istio-service-mesh.svg")} />
</center>

<center>
  <strong>After utilizing Istio</strong>
</center>

```txt
Client ─── Service A ┬── Service B
                     └── Service C
```

`Client`가 `Service A`에 어떤 요청을 하냐에 따라 `Service B` 또는 `Service C`를 호출하는 시스템이 있다고 가정합니다.

`Service B`에 문제가 발생해서 `Service A`로부터의 호출에 응답을 못하면 `Service A`의 한 스레드가 대기 상태에 들어가게 될 수 있습니다. 이러한 상황이 반복되면 대기중인 스레드가 많아지고, 그 결과 `Service A`가 멈출 수 있고, `Service C`를 호출해서 진행되는 과정에도 문제가 발생할 수 있습니다.

```txt
Client ─── Service A ┬── Circuit breaker B ─── Service B
                     └── Circuit breaker C ─── Service C
```

이러한 지연을 감지하여 네트워크를 끊어주는 서킷 브레이커(Circuit breaker)를 서비스들 사이에 추가하면 문제가 발생했을 때, 네트워크가 끊기면서 `Service A`의 대기 중인 스레드가 통신 에러를 감지하게 되고 그에 따라 스레드를 정리할 수 있습니다. 그렇게 되면 `Service C`를 이용하던 서비스는 문제없이 제공될 수 있습니다.

```txt
Client ─── Service A ─── Proxy A ┬── Proxy B ─── Service B
                                 └── Proxy C ─── Service C
```

통신 장애 처리 외에도, 통신 흐름을 제어하거나 통신 흐름을 모니터링하는 등 다양한 문제가 있는데, 서비스들을 직접 연결하는 것이 아니라 서비스 사이에 프록시를 추가하여 연결하면 이러한 문제를 해결할 수 있습니다.

```txt
Client ─── Service A ─── Proxy A ┬── Proxy B ─── Service B
                                 └── Proxy C ─── Service C
Client ─── Service D ─── Proxy D ┬── Proxy E ─── Service E
                                 └── Proxy F ─── Service F

...

Control Plane
```

서비스 규모가 작을 때는 직접 프록시 설정을 변경해가며 네트워크를 구성할 수 있지만 규모가 커지면 설정이 어려워집니다. 프록시들(`Data Plane`)을 한 번에 관리할 수 있는 `Control Plane`을 추가하면 이러한 문제를 해결 할 수 있습니다.

이렇게 서비스간 통신을 관리하기 위해 구축한 전용 인프라 계층을 서비스 메쉬라고 합니다.

## Envoy

`Envoy`는 L7 프록시로 Istio에서는 수정된 Envoy가 사용됩니다.

사이드카(sidecar)란 Pod에 기능을 추가하기 위해 추가된 컨테이너를 말하는 데, Istio는 Pod가 생성될 때 Injection rules에 따라 Envoy를 사이드카로 추가합니다.

| Resource  | Label                   | Enabled value | Disabled value |
| --------- | ----------------------- | ------------- | -------------- |
| Namespace | istio-injection         | enabled       | disabled       |
| Pod       | sidecar.istio.io/inject | true          | false          |

revision을 활용하는 경우 아래와 같은 방식으로도 활성/비활성을 설정할 수 있습니다.

| Resource  | Enabled label       | Disabled label                  |
| --------- | ------------------- | ------------------------------- |
| Namespace | istio.io/rev=1-14-5 | istio-injection=disabled        |
| Pod       | istio.io/rev=1-14-5 | sidecar.istio.io/inject="false" |

### Injection rule examples

아래와 같이 설정한 파일을 `Kustomize`를 사용하여 패치하면 같이 설정되는 모든 `Deployment`에 사이드카가 주입됩니다.

```yaml title="kubeflow/common/knative/knative-serving/base/patches/sidecar-injection.yaml" {10}
patches:
apiVersion: apps/v1
kind: Deployment
metadata:
  name: "*"
spec:
  template:
    metadata:
      labels:
        sidecar.istio.io/inject: "true"
```

아래와 같이 설정한 경우 해당 `Namespace`에 있는 Pod에는 사이드카가 주입되지 않습니다.

```yaml title="kubeflow/manifests/common/istio-1-9-0/istio-namespace/base/namespace.yaml" {7}
apiVersion: v1
kind: Namespace
metadata:
  name: istio-system
  labels:
    istio-operator-managed: Reconcile
    istio-injection: disabled
```

아래 명령으로 namespace에 `istio-injection` 라벨을 추가/변경/제거/확인 할 수 있습니다.

```shell
kubectl label namespace <namespace> istio-injection=<enabled|disabled>
```

```shell
kubectl label namespace <namespace> istio-injection-
```

```shell
kubectl get namespace -L istio-injection
```

## Gateway & VirtualService

```yaml {12}
apiVersion: v1
kind: Service
metadata:
  labels:
    app: ml-pipeline-ui
  name: ml-pipeline-ui
  namespace: kubeflow
spec:
  ports:
    - name: http
      protocol: TCP
      port: 80
      targetPort: 3000
  selector:
    app: ml-pipeline-ui
```

```yaml {14,16}
apiVersion: networking.istio.io/v1alpha3
kind: VirtualService
metadata:
  name: ml-pipeline-ui
  namespace: istio-system
spec:
  hosts:
    - "kubeflow.loliot.net"
  gateways:
    - istio-gateway
  http:
    - route:
        - destination:
            host: ml-pipeline-ui.kubeflow.svc.cluster.local
            port:
              number: 80
```

```yaml {}
apiVersion: networking.istio.io/v1alpha3
kind: Gateway
metadata:
  name: istio-gateway
  namespace: istio-system
spec:
  selector:
    istio: ingressgateway
  servers:
    - port:
        number: 80
        name: http-kubeflow
        protocol: HTTP
      tls:
        httpsRedirect: true
      hosts:
        - "kubeflow.loliot.net"
    - port:
        number: 443
        name: https-kubeflow
        protocol: HTTPS
      tls:
        mode: SIMPLE
        credentialName: ingress-cert-tls
      hosts:
        - "kubeflow.loliot.net"
```

## Reference

- [https://bcho.tistory.com/1293](https://bcho.tistory.com/1293)
- [https://istio.io/latest/about/service-mesh/](https://istio.io/latest/about/service-mesh/)
- [https://istio.io/latest/docs/reference/config/istio.operator.v1alpha1/](https://istio.io/latest/docs/reference/config/istio.operator.v1alpha1/)
- [https://istio.io/latest/docs/examples/bookinfo/](https://istio.io/latest/docs/examples/bookinfo/)
